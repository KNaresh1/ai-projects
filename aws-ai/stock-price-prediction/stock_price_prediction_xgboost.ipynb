{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Stock Price Prediction using `XGBoost` Algorithm\n",
    "\n",
    "> 1. Build and train an Amazon SageMaker model<br>\n",
    "> 2. Deploy and test the Amazon SageMaker model endpoint<br>\n",
    "> 3. Create an AWS Lambda function\n",
    "> 4. Build, deploy and test an API Gateway endpoint for the REST API"
   ],
   "id": "b406dc040a7afb5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Build and train an Amazon SageMaker model<br>\n",
    "#### 1.1 Create a S3 Bucket\n",
    "**Boto3** is the **Amazon Web Services (AWS) Software Development Kit (SDK)** for Python, which allows you to directly create, update, and delete AWS resources from your Python scripts.\n",
    "\n",
    "Boto3 makes it easy to integrate yours Python application, library, or script with AWS services including Amazon S3, Amazon EC2, DynamoDB, and more."
   ],
   "id": "1fbaabfc434b1fa3"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import boto3\n",
    "from pyasn1_modules.rfc5126 import ContentType\n",
    "\n",
    "s3 = boto3.client('s3')"
   ],
   "id": "7aa8cfe38f67c8f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:24:11.127780Z",
     "start_time": "2024-11-23T03:24:10.826640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bucket_name = 'yf-stock-price-prediction'\n",
    "\n",
    "try:\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print(\"S3 Bucket has been created successfully\")\n",
    "except Exception as e:\n",
    "    print('S3 error: ', e)"
   ],
   "id": "31543c099992ee7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Bucket has been created successfully\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2. Create train and validation csv",
   "id": "73af77564a83ddfe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:19:48.367558Z",
     "start_time": "2024-11-23T03:19:45.308990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "# Initialize\n",
    "start_date = datetime(2021, 1, 1)\n",
    "end_date = datetime(2024, 11, 15)\n",
    "\n",
    "# Get the data\n",
    "df_data = yf.download('AAPL', start = start_date, end = end_date)\n",
    "df_data.reset_index(inplace=True)\n",
    "print(df_data)"
   ],
   "id": "e7be4f6ceebab08c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                       Date   Adj Close       Close        High  \\\n",
      "Ticker                                  AAPL        AAPL        AAPL   \n",
      "0      2021-01-04 00:00:00+00:00  126.544205  129.410004  133.610001   \n",
      "1      2021-01-05 00:00:00+00:00  128.108765  131.009995  131.740005   \n",
      "2      2021-01-06 00:00:00+00:00  123.796432  126.599998  131.050003   \n",
      "3      2021-01-07 00:00:00+00:00  128.020782  130.919998  131.630005   \n",
      "4      2021-01-08 00:00:00+00:00  129.125763  132.050003  132.630005   \n",
      "..                           ...         ...         ...         ...   \n",
      "969    2024-11-08 00:00:00+00:00  226.960007  226.960007  228.660004   \n",
      "970    2024-11-11 00:00:00+00:00  224.229996  224.229996  225.699997   \n",
      "971    2024-11-12 00:00:00+00:00  224.229996  224.229996  225.589996   \n",
      "972    2024-11-13 00:00:00+00:00  225.119995  225.119995  226.649994   \n",
      "973    2024-11-14 00:00:00+00:00  228.220001  228.220001  228.869995   \n",
      "\n",
      "Price          Low        Open     Volume  \n",
      "Ticker        AAPL        AAPL       AAPL  \n",
      "0       126.760002  133.520004  143301900  \n",
      "1       128.429993  128.889999   97664900  \n",
      "2       126.379997  127.720001  155088000  \n",
      "3       127.860001  128.360001  109578200  \n",
      "4       130.229996  132.429993  105158200  \n",
      "..             ...         ...        ...  \n",
      "969     226.410004  227.169998   38328800  \n",
      "970     221.500000  225.000000   42005600  \n",
      "971     223.360001  224.550003   40398300  \n",
      "972     222.759995  224.009995   48566200  \n",
      "973     225.000000  225.020004   44923900  \n",
      "\n",
      "[974 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " #### 1.3. Extract, Load & Transform",
   "id": "34b15662ed8ccd25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:20:00.520542Z",
     "start_time": "2024-11-23T03:20:00.515298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop unnecessary columns from the data table\n",
    "\n",
    "# The column in the DataFrame has a MultiIndex with two levels: Price and Ticker.\n",
    "\n",
    "# Now, drop the columns\n",
    "df_data.drop(columns=[('Date', ''), ('Adj Close', 'AAPL')], inplace=True)\n",
    "print(df_data)\n"
   ],
   "id": "e7c716d36e3f798c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        Close        High         Low        Open     Volume\n",
      "Ticker        AAPL        AAPL        AAPL        AAPL       AAPL\n",
      "0       129.410004  133.610001  126.760002  133.520004  143301900\n",
      "1       131.009995  131.740005  128.429993  128.889999   97664900\n",
      "2       126.599998  131.050003  126.379997  127.720001  155088000\n",
      "3       130.919998  131.630005  127.860001  128.360001  109578200\n",
      "4       132.050003  132.630005  130.229996  132.429993  105158200\n",
      "..             ...         ...         ...         ...        ...\n",
      "969     226.960007  228.660004  226.410004  227.169998   38328800\n",
      "970     224.229996  225.699997  221.500000  225.000000   42005600\n",
      "971     224.229996  225.589996  223.360001  224.550003   40398300\n",
      "972     225.119995  226.649994  222.759995  224.009995   48566200\n",
      "973     228.220001  228.869995  225.000000  225.020004   44923900\n",
      "\n",
      "[974 rows x 5 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:20:07.874425Z",
     "start_time": "2024-11-23T03:20:07.870208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove last row as that is what we are going to predict (next day data)\n",
    "\n",
    "# (df.iloc[rows, columns])\n",
    "df_data_features = df_data.iloc[:-1, :]\n",
    "\n",
    "print(df_data_features)"
   ],
   "id": "6d10e98bd01d7b34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        Close        High         Low        Open     Volume\n",
      "Ticker        AAPL        AAPL        AAPL        AAPL       AAPL\n",
      "0       129.410004  133.610001  126.760002  133.520004  143301900\n",
      "1       131.009995  131.740005  128.429993  128.889999   97664900\n",
      "2       126.599998  131.050003  126.379997  127.720001  155088000\n",
      "3       130.919998  131.630005  127.860001  128.360001  109578200\n",
      "4       132.050003  132.630005  130.229996  132.429993  105158200\n",
      "..             ...         ...         ...         ...        ...\n",
      "968     227.479996  227.880005  224.570007  224.630005   42137700\n",
      "969     226.960007  228.660004  226.410004  227.169998   38328800\n",
      "970     224.229996  225.699997  221.500000  225.000000   42005600\n",
      "971     224.229996  225.589996  223.360001  224.550003   40398300\n",
      "972     225.119995  226.649994  222.759995  224.009995   48566200\n",
      "\n",
      "[973 rows x 5 columns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:20:12.734557Z",
     "start_time": "2024-11-23T03:20:12.731170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract the 'Open' column as that is the target Row-1 (next data) price prediction\n",
    "df_data_targets = df_data.loc[1:, ('Open', 'AAPL')].rename('Targets')\n",
    "\n",
    "print(df_data_targets)"
   ],
   "id": "bafb234647a5f954",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      128.889999\n",
      "2      127.720001\n",
      "3      128.360001\n",
      "4      132.429993\n",
      "5      129.190002\n",
      "          ...    \n",
      "969    227.169998\n",
      "970    225.000000\n",
      "971    224.550003\n",
      "972    224.009995\n",
      "973    225.020004\n",
      "Name: Targets, Length: 973, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:38:17.957633Z",
     "start_time": "2024-11-23T04:38:17.950267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assign the target column using .loc to avoid the SettingWithCopyWarning\n",
    "df_data_features.loc[:, 'Target'] = list(df_data_targets)\n",
    "\n",
    "# For `XGBoost` to work we should have `Target` as first column\n",
    "first_column = df_data_features.pop('Target')\n",
    "df_data_features.insert(loc=0, column='Target', value=first_column)\n",
    "\n",
    "df_data_final = df_data_features.copy()\n",
    "print(df_data_final)"
   ],
   "id": "127401df0bd98639",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price       Target       Close        High         Low        Open     Volume\n",
      "Ticker                    AAPL        AAPL        AAPL        AAPL       AAPL\n",
      "0       128.889999  129.410004  133.610001  126.760002  133.520004  143301900\n",
      "1       127.720001  131.009995  131.740005  128.429993  128.889999   97664900\n",
      "2       128.360001  126.599998  131.050003  126.379997  127.720001  155088000\n",
      "3       132.429993  130.919998  131.630005  127.860001  128.360001  109578200\n",
      "4       129.190002  132.050003  132.630005  130.229996  132.429993  105158200\n",
      "..             ...         ...         ...         ...         ...        ...\n",
      "968     227.169998  227.479996  227.880005  224.570007  224.630005   42137700\n",
      "969     225.000000  226.960007  228.660004  226.410004  227.169998   38328800\n",
      "970     224.550003  224.229996  225.699997  221.500000  225.000000   42005600\n",
      "971     224.009995  224.229996  225.589996  223.360001  224.550003   40398300\n",
      "972     225.020004  225.119995  226.649994  222.759995  224.009995   48566200\n",
      "\n",
      "[973 rows x 6 columns]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.4. Train Test Split",
   "id": "ab3ba935ab9883e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:20:22.773890Z",
     "start_time": "2024-11-23T03:20:20.609950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(df_data_final, test_size=0.2, random_state=123)\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ],
   "id": "443a835fffe36309",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778, 6) (195, 6)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:20:27.667018Z",
     "start_time": "2024-11-23T03:20:27.663922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prefix = 'xgboost-algorithm'\n",
    "\n",
    "# SageMaker Python SDK 2.0 format\n",
    "train_csv_path = 's3://{}/{}/{}/{}'.format(bucket_name, prefix, 'train', 'train.csv')\n",
    "test_csv_path = 's3://{}/{}/{}/{}'.format(bucket_name, prefix, 'test', 'test.csv')\n",
    "\n",
    "print(train_csv_path)\n",
    "print(test_csv_path)\n"
   ],
   "id": "50e00d458453b73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://yf-stock-price-prediction/xgboost-algorithm/train/train.csv\n",
      "s3://yf-stock-price-prediction/xgboost-algorithm/test/test.csv\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:24:27.050423Z",
     "start_time": "2024-11-23T03:24:25.755633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data.to_csv(train_csv_path, index=False, header=False)\n",
    "test_data.to_csv(test_csv_path, index=False, header=False)"
   ],
   "id": "8443d38477a32e14",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.5. Build `XGBoost` Model<br>\n",
    "#### How to Use SageMaker XGBoost\n",
    "With SageMaker, we can use `XGBoost` as a built-in algorithm or framework. By using XGBoost as a framework, we have more flexibility and access to more advanced scenarios, such as k-fold cross-validation, because we can customize our own training scripts\n",
    "\n",
    "\n",
    "> #### Use XGBoost as a framework\n",
    "Use XGBoost as a framework to run our customized training scripts that can incorporate additional data processing into our training jobs\n",
    "\n",
    "> #### Use XGBoost as a built-in algorithm\n",
    "Use the XGBoost built-in algorithm to build an XGBoost training container"
   ],
   "id": "47ed8c9a807c3497"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:38:11.060040Z",
     "start_time": "2024-11-23T04:38:11.057412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I am using the approach XGBoost as a built-in algorithm\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput"
   ],
   "id": "60aa68389d77031e",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.6. Find an `XGBoost` image uri and build an XGBoost container",
   "id": "c5cc8dd60932e405"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgboost_container = image_uris.retrieve('xgboost', boto3.Session().region_name, '1.5-1')\n",
    "\n",
    "print(xgboost_container)"
   ],
   "id": "9ea85a6f977573ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.7. Initialize hyperparameters<br>\n",
    "#### Booster Parameters:\n",
    "> **max_depth** - Maximum depth of a tree. Increasing the value makes the model more complex \n",
    "\n",
    "> **eta** - Step size shrinkage used in updates to prevent overfitting\n",
    "\n",
    "> **gamma** - Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "\n",
    "> **min_child_weight** - Minimum sum of instance weight needed in a child\n",
    "\n",
    "> **subsample** - Subsample ratio of the training instance\n",
    "\n",
    "#### Learning Task Parameter:\n",
    "> **objective** - Specifies the learning task and the corresponding learning objective"
   ],
   "id": "77d886285ac518fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:25:00.716082Z",
     "start_time": "2024-11-23T03:25:00.713658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": '5',\n",
    "    \"eta\": '0.2',\n",
    "    \"gamma\": '4',\n",
    "    \"min_child_weight\": '6',\n",
    "    \"subsample\": '0.7',\n",
    "    \"objective\": 'reg:squarederror',\n",
    "    \"early_stopping_rounds\": 10,\n",
    "    \"num_round\": 1000\n",
    "}"
   ],
   "id": "588b3459c58a9385",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.8. Set an output path where the trained model will be saved",
   "id": "7358b9f01f398ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T03:25:08.641668Z",
     "start_time": "2024-11-23T03:25:08.639410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_path = 's3://{}/{}/{}/'.format(bucket_name, prefix, 'output')\n",
    "\n",
    "print(output_path)"
   ],
   "id": "df08d8b829260ce2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://yf-stock-price-prediction/xgboost-algorithm/output/\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1.9. Construct a SageMaker estimator that calls the xgboost-container<br>\n",
    "> Enable the **train_use_spot_instances** constructor arg - a simple self-explanatory boolean\n",
    "\n",
    "> Set the **train_max_wait** constructor arg\n",
    "\n",
    "> **train_max_run** - The timeout in seconds for training"
   ],
   "id": "e41f710bc0c619e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### `Run sagemaker-role-creation CFT which creates required role, then use the role arn in the below section`",
   "id": "e842a9ca1a2a94e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:22:55.074079Z",
     "start_time": "2024-11-23T04:22:55.051929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container,\n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          output_path=output_path,\n",
    "                                          role='<sagemaker-role-arn>',\n",
    "                                          instance_count=1,\n",
    "                                          instance_type='ml.m5.xlarge',\n",
    "                                          volume_size_in_gb=5,\n",
    "                                          use_spot_instances=False,\n",
    "                                          max_run=300\n",
    "                                          )"
   ],
   "id": "610e00d9136e0037",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.10. Define the data type and paths to the training and validation datasets",
   "id": "48d1dab8cd54e3b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:22:58.749729Z",
     "start_time": "2024-11-23T04:22:58.747606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content_type = 'csv'\n",
    "train_input = TrainingInput('s3://{}/{}/{}/'.format(bucket_name, prefix, 'train'), content_type=content_type)\n",
    "test_input = TrainingInput('s3://{}/{}/{}/'.format(bucket_name, prefix, 'test'), content_type=content_type)"
   ],
   "id": "e468eb47d9a2c0f6",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.11. Execute the `XGBoost` training job",
   "id": "493759cb9bfe4559"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:25:54.205725Z",
     "start_time": "2024-11-23T04:23:02.383721Z"
    }
   },
   "cell_type": "code",
   "source": "estimator.fit({\"train\": train_input, \"validation\": test_input})",
   "id": "9d7a1ea17ab1aef6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-11-23-04-23-02-384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-23 04:23:04 Starting - Starting the training job...\n",
      "2024-11-23 04:23:19 Starting - Preparing the instances for training...\n",
      "2024-11-23 04:24:06 Downloading - Downloading the training image......\n",
      "2024-11-23 04:24:51 Training - Training image download completed. Training in progress....\n",
      "2024-11-23 04:25:25 Uploading - Uploading generated training model\n",
      "2024-11-23 04:25:25 Completed - Training job completed\n",
      "..Training seconds: 105\n",
      "Billable seconds: 105\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Deploy and test the Amazon SageMaker model endpoint<br>\n",
    "#### 2.1. Deploy trained `XGBoost` model as Endpoint\n",
    " 1. Environment\n",
    " > Within SageMaker - Serialization by User<br>\n",
    " > **Outside SageMaker - Serialization by Endpoint**\n",
    " \n",
    "2. Method to invoke the Endpoint\n",
    "> **API - Single Prediction**<br>\n",
    "> S3 Bucket - Batch Prediction\n",
    "\n",
    "3. Data type based on method\n",
    "> **API - JSON**<br>\n",
    "> S3 Bucket - CSV\n",
    "\n",
    "To host a model through Amazon EC2 using Amazon SageMaker, deploy the model that you trained in Create and Run a Training Job by calling the **deploy method** of the **xgb_model estimator**\n",
    "\n",
    "When you call the deploy method, few key things that you need to specify\n",
    "> **initial_instance_count (int)** - The number of instances to deploy the model\n",
    "\n",
    "> **instance_type (str)** - The type of instances that you want to operate your deployed model\n",
    "\n",
    "> **serializer (int)** - The type of instance that you want to operate your deployed model"
   ],
   "id": "da16fb303702f617"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:31:41.576712Z",
     "start_time": "2024-11-23T04:28:08.917308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "csv_serializer = CSVSerializer()\n",
    "xgb_predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m5.large', serializer=csv_serializer)"
   ],
   "id": "7026af1773a17fd7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-11-23-04-28-08-918\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2024-11-23-04-28-08-918\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2024-11-23-04-28-08-918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(xgb_predictor.endpoint_name)",
   "id": "6a00125e995fa7cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2. Make prediction with the use of Endpoints",
   "id": "14ae67ea6845e673"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:32:18.152510Z",
     "start_time": "2024-11-23T04:32:17.720841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize\n",
    "start_date = datetime(2024, 11, 14)\n",
    "end_date = datetime(2024, 11, 15)\n",
    "\n",
    "# Get the data\n",
    "df_data = yf.download('AAPL', start = start_date, end = end_date)\n",
    "df_data.reset_index(inplace=True)\n",
    "print(df_data)"
   ],
   "id": "9638cf7bc1852129",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                       Date   Adj Close       Close        High    Low  \\\n",
      "Ticker                                  AAPL        AAPL        AAPL   AAPL   \n",
      "0      2024-11-14 00:00:00+00:00  228.220001  228.220001  228.869995  225.0   \n",
      "\n",
      "Price         Open    Volume  \n",
      "Ticker        AAPL      AAPL  \n",
      "0       225.020004  44923900  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:32:23.193064Z",
     "start_time": "2024-11-23T04:32:23.189316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop unwanted columns\n",
    "\n",
    "df_data.drop(columns=[('Date', ''), ('Adj Close', 'AAPL')], inplace=True)\n",
    "\n",
    "data_features = df_data.values\n",
    "print(data_features)"
   ],
   "id": "c22d8c3c77e5a8b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.28220001e+02 2.28869995e+02 2.25000000e+02 2.25020004e+02\n",
      "  4.49239000e+07]]\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.3. Inference - Serialized Input by build-in function (Lambda function friendly)",
   "id": "eab342c92379ba70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:35:57.151340Z",
     "start_time": "2024-11-23T04:35:57.090914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Input = [[2.25000000e+02, 2.26919998e+02, 2.24270004e+02, 2.26399994e+02, 4.78322000e+07]]\n",
    "\n",
    "Serialized_Input = ','.join(map(str, Input[0]))\n",
    "\n",
    "print('Serialized_Input...:', Serialized_Input)\n",
    "\n",
    "Y_pred = xgb_predictor.predict(Serialized_Input).decode('utf-8')\n",
    "print(f\"Predicted Stock Price: ${Y_pred}\")"
   ],
   "id": "70d97a73a7b7aff9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized_Input...: 225.0,226.919998,224.270004,226.399994,47832200.0\n",
      "Predicted Stock Price: $226.04385375976562\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Create an AWS Lambda function<br>\n",
    "#### 3.1. Lambda function handler - Copy & Paste below lambda handler code to a new Lambda created in aws console"
   ],
   "id": "47a3eeb5e0e70eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:33:14.542889Z",
     "start_time": "2024-11-23T04:33:14.529093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import boto3\n",
    "\n",
    "ENDPOINT_NAME = '<sagemaker-endpoint-name>'\n",
    "runtime = boto3.client('runtime.sagemaker')\n",
    "email_client = boto3.client('sns')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    inputs = event['data']\n",
    "    \n",
    "    result = []\n",
    "    for input_data in inputs:\n",
    "        serialized_input = ','.join(map(str, input_data))\n",
    "        response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType='text/csv', Body=serialized_input)\n",
    "        prediction = response['Body'].read().decode().strip()\n",
    "        result.append(prediction)\n",
    "        \n",
    "    # Publish result to a topic which in turn sends the predictions to all the subscribers of the topic\n",
    "    '''response_sns = email_client.publish(\n",
    "        TopicArn = 'Arn of the created topic',\n",
    "        Message = 'Prediction is ' + str(result),\n",
    "        Subject = 'NK Finance Daily - Price Prediction')\n",
    "    '''\n",
    "    \n",
    "    return result"
   ],
   "id": "171350348f17e5dc",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T04:33:19.378459Z",
     "start_time": "2024-11-23T04:33:19.065928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# To test the lambda function locally\n",
    "\n",
    "Input_json = { \n",
    "        \"data\": [\n",
    "            [2.25000000e+02, 2.26919998e+02, 2.24270004e+02, 2.26399994e+02, 4.78322000e+07],\n",
    "            [2.25000000e+02, 2.26919998e+02, 2.24270004e+02, 2.26399994e+02, 4.78322000e+07]\n",
    "        ]\n",
    "}\n",
    "\n",
    "result1 = lambda_handler(Input_json, None)\n",
    "print(result1)"
   ],
   "id": "fdbe80782785335f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['226.04385375976562', '226.04385375976562']\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 3.2. Create SNS Topic to send emails to users with price prediction<br>\n",
    "> 1. Now under SNS select A2P (Application-to-person) communication to send the predicted price to user email\n",
    "> 2. Create a top and add a subscription as user email\n",
    "> 3. User receives an email to confirm their subscription\n",
    "> 4. Copy the topic's arn and provide it in the above lambda handler in the push functions section\n",
    "> 5. Update the iam role to attach the SNS policy for lambda to access the topic"
   ],
   "id": "cbd9544f596ad940"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Build, deploy and test an API Gateway endpoint for the REST API<br>\n",
    "> 1. Create REST API Gateway with a POST method and integrate the lambda\n",
    "> 2. Now POST api call using api gateway endpoint should direct to lambda and return response to client"
   ],
   "id": "8ff14bf18cc44421"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import requests\n",
    "\n",
    "API_ENDPOINT = '<api-gateway-endpoint>'\n",
    "\n",
    "json_request = { \n",
    "        \"data\": [\n",
    "            [2.25000000e+02, 2.26919998e+02, 2.24270004e+02, 2.26399994e+02, 4.78322000e+07],\n",
    "            [2.25000000e+02, 2.26919998e+02, 2.24270004e+02, 2.26399994e+02, 4.78322000e+07]\n",
    "        ]\n",
    "}\n",
    "\n",
    "response = requests.post(url=API_ENDPOINT, json=json_request)"
   ],
   "id": "91bfbd3eec14b24e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f\"Status Code: {response.status_code}, Response: {response.json()}\")",
   "id": "bf9dd1a81b77d414"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Cleanup and Terminate",
   "id": "a477c230637a22c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#sagemaker.Session().delete_endpoint(endpoint_name=xgb_predictor.endpoint_name)\n",
    "#sagemaker.Session().delete_endpoint_config(endpoint_config_name=xgb_predictor.endpoint_name)\n",
    "#sagemaker.Session().delete_model(model_name=xgb_predictor.endpoint_name)"
   ],
   "id": "7cf73011833eee9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#bucket_to_delete = boto3.resource(\"s3\").Bucket(bucket_name)\n",
    "#bucket_to_delete.objects.all().delete()\n",
    "#bucket_to_delete.delete()"
   ],
   "id": "7d12d64f74c018ab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
